\subsection{Data Acquisition and Preprocessing}
The dataset for this project will be constructed from publicly available NBA game data, sourced from sports statistics APIs (e.g., nba\_api) or comprehensive basketball data websites (e.g., Basketball-Reference.com). The dataset will encompass all 105 games (82 regular season, 23 playoff) played by the Indiana Pacers during the 2024-2025 season.

For each of these 105 games, we will collect:
\begin{enumerate}
    \item[-] Game-level data: Date, opponent, location (home/away), and final score.
    \item[-] Player-level data: Detailed box scores for every player who participated in each game (for both the Pacers and their opponent). This includes minutes played (MP) and standard counting stats (points, rebounds, assists, steals, blocks, turnovers, fouls, FGA, FGM, 3PA, 3PM, FTA, FTM).
\end{enumerate}
The raw data will be preprocessed into a structured format where each row represents a single game $(N=105)$. The primary target variable will be a binary outcome: Pacers\_Win (1 for a win, 0 for a loss). All other collected data will be used to engineer predictive features. Preprocessing will also involve handling missing values, such as for players who were on the roster but did not play (DNP).

\subsection{Feature Engineering: Player Archetypes}

A central component of our methodology is to move beyond individual player statistics and model the composition of the lineups. As proposed in the abstract, we will operationalize this by creating "player archetypes."

\begin{itemize}
    \item Archetype Clustering: We will apply a K-Means clustering algorithm to define these archetypes. The clustering will be performed on a normalized dataset of all players (from both the Pacers and their opponents) who played significant minutes during the season. The features used for clustering will include per-36-minute statistics and advanced metrics (e.g., True Shooting Percentage (TS\%), Usage Rate (USG\%), Assist Rate, Rebound Rate) to capture a player's style and on-court role.
    \item Archetype Labeling: After clustering, we will manually inspect the statistical profile of each cluster to assign a descriptive label.
    \item Game-level Feature Vector: For each of the 105 games, we will create a feature vector representing the lineup composition. This vector will be a count of how many players belonging to each archetype were among the top five minute-getters for that game. This will be done for both the Pacers and their opponent.
\end{itemize}

\subsubsection{The final feature set for each game will include}

\begin{itemize}
    \item Pacers\_Archetype\_1\_Count
    \item Pacers\_Archetype\_2\_count
    \item \ldots
    \item Opponent\_Archetype\_1\_Count
    \item Opponent\_Archetype\_2\_Count
    \item \ldots
    \item Game\_Location (0 for Away, 1 for Home)
\end{itemize}

This approach directly models the interaction of lineup archetypes, addressing the hypothesis that the type of opponent impacts the Pacers' win probability.

\subsection{Model Development and Evaluation}

Given the binary nature of our target variable (Pacers\_Win), this project will formulate the problem as a binary classification task. Due to the small dataset size $(N=105)$, we will prioritize models that are less prone to overfitting and offer high interpretability.

\subsubsection{Selected Models}
We will implement and compare several classification algorithms:
\begin{itemize}
    \item \textbf{Logistic Regression}: A baseline model that is highly interpretable, allowing us to quantify how the presence of specific Pacers or opponent archetypes directly impacts the log-odds of winning.
    \item \textbf{K-Nearest Neighbors (K-NN)}: This model works by finding the 'k' most similar games from the past (the "nearest neighbors") and then predicting the outcome based on how those similar games turned out. It's a good, straightforward approach for a "pattern matching" problem like this.
    \item \textbf{Naive Bayes}: The Naive Bayes probabilistic classifier calculates the likelihood of a win or loss given the lineup archetypes. Since the dataset is smaller, this classifier could perform quite well.
\end{itemize}
\subsubsection{Model Validation}
A simple train-test split would be unreliable with only 105 data points. Therefore, we will employ 10-fold cross-validation to generate a stronger estimate of each model's performance. The data will be shuffled and split into 10 subsets; the model will be trained 10 times, each time using 9 of the subsets for training and 1 for testing.

Evaluation Metrics: Model performance will be assessed using a suite of standard classification metrics:
\begin{itemize}
    \item \textbf{Accuracy}: The overall percentage of correctly predicted game outcomes.
    \item \textbf{Precision, Recall, and F1-Score}: These metrics are especially crucial if the win-loss record is imbalanced (e.g., if the Pacers had a 70-win season, a model that always predicts "Win" would have high accuracy but zero utility).
\end{itemize}

The deliverable will be a model that is highly accurate and provides actionable insights into which lineup compositions and opponent archetypes led to wins and losses for the 2024-2025 Pacers.